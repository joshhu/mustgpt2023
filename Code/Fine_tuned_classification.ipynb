{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tuning classification example\n",
        "\n",
        "We will fine-tune an ada classifier to distinguish between the two sports: Baseball and Hockey."
      ],
      "metadata": {
        "id": "eQ-xu9_BJycN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZhCM4pyKAcG",
        "outputId": "389047e0-2028-408c-97dc-cc9f28224eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import pandas as pd\n",
        "import openai\n",
        "\n",
        "categories = ['rec.sport.baseball', 'rec.sport.hockey']\n",
        "sports_dataset = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, categories=categories)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Uaao1d7UJycO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0bDGmwNHJ_d8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UKskDkF0J-Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Data exploration\n",
        " The newsgroup dataset can be loaded using sklearn. First we will look at the data itself:"
      ],
      "metadata": {
        "id": "TezA5sy2JycP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(sports_dataset['data'][0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: dougb@comm.mot.com (Doug Bank)\n",
            "Subject: Re: Info needed for Cleveland tickets\n",
            "Reply-To: dougb@ecs.comm.mot.com\n",
            "Organization: Motorola Land Mobile Products Sector\n",
            "Distribution: usa\n",
            "Nntp-Posting-Host: 145.1.146.35\n",
            "Lines: 17\n",
            "\n",
            "In article <1993Apr1.234031.4950@leland.Stanford.EDU>, bohnert@leland.Stanford.EDU (matthew bohnert) writes:\n",
            "\n",
            "|> I'm going to be in Cleveland Thursday, April 15 to Sunday, April 18.\n",
            "|> Does anybody know if the Tribe will be in town on those dates, and\n",
            "|> if so, who're they playing and if tickets are available?\n",
            "\n",
            "The tribe will be in town from April 16 to the 19th.\n",
            "There are ALWAYS tickets available! (Though they are playing Toronto,\n",
            "and many Toronto fans make the trip to Cleveland as it is easier to\n",
            "get tickets in Cleveland than in Toronto.  Either way, I seriously\n",
            "doubt they will sell out until the end of the season.)\n",
            "\n",
            "-- \n",
            "Doug Bank                       Private Systems Division\n",
            "dougb@ecs.comm.mot.com          Motorola Communications Sector\n",
            "dougb@nwu.edu                   Schaumburg, Illinois\n",
            "dougb@casbah.acns.nwu.edu       708-576-8207                    \n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2F9f3eiJycP",
        "outputId": "274ed56d-ef59-489f-b5d0-9f5d50414553"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sports_dataset.target_names[sports_dataset['target'][0]]\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rec.sport.baseball'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qY40JZ8LJycP",
        "outputId": "b5d55ab0-c6aa-46ea-bbb1-f23560f63c7c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "len_all, len_baseball, len_hockey = len(sports_dataset.data), len([e for e in sports_dataset.target if e == 0]), len([e for e in sports_dataset.target if e == 1])\n",
        "print(f\"Total examples: {len_all}, Baseball examples: {len_baseball}, Hockey examples: {len_hockey}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total examples: 1197, Baseball examples: 597, Hockey examples: 600\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhiGIwtEJycP",
        "outputId": "12f68d10-1a0b-455a-f111-400541e13424"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One sample from the baseball category can be seen above. It is an email to a mailing list. We can observe that we have 1197 examples in total, which are evenly split between the two sports."
      ],
      "metadata": {
        "id": "4osTkbsuJycQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation\n",
        "We transform the dataset into a pandas dataframe, with a column for prompt and completion. The prompt contains the email from the mailing list, and the completion is a name of the sport, either hockey or baseball. For demonstration purposes only and speed of fine-tuning we take only 300 examples. In a real use case the more examples the better the performance."
      ],
      "metadata": {
        "id": "TjCo9CLgJycQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pandas as pd\n",
        "\n",
        "labels = [sports_dataset.target_names[x].split('.')[-1] for x in sports_dataset['target']]\n",
        "texts = [text.strip() for text in sports_dataset['data']]\n",
        "df = pd.DataFrame(zip(texts, labels), columns = ['prompt','completion']) #[:300]\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              prompt completion\n",
              "0  From: dougb@comm.mot.com (Doug Bank)\\nSubject:...   baseball\n",
              "1  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...     hockey\n",
              "2  From: rudy@netcom.com (Rudy Wade)\\nSubject: Re...   baseball\n",
              "3  From: monack@helium.gas.uug.arizona.edu (david...     hockey\n",
              "4  Subject: Let it be Known\\nFrom: <ISSBTL@BYUVM....   baseball"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6c5429c-3baf-4d10-8e18-24ddef24ffd0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>completion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: dougb@comm.mot.com (Doug Bank)\\nSubject:...</td>\n",
              "      <td>baseball</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
              "      <td>hockey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: rudy@netcom.com (Rudy Wade)\\nSubject: Re...</td>\n",
              "      <td>baseball</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: monack@helium.gas.uug.arizona.edu (david...</td>\n",
              "      <td>hockey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: Let it be Known\\nFrom: &lt;ISSBTL@BYUVM....</td>\n",
              "      <td>baseball</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6c5429c-3baf-4d10-8e18-24ddef24ffd0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f6c5429c-3baf-4d10-8e18-24ddef24ffd0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f6c5429c-3baf-4d10-8e18-24ddef24ffd0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z2nOkAhlJycQ",
        "outputId": "690ee09a-d9b5-4724-eb8b-e0d0f47b601b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both baseball and hockey are single tokens. We save the dataset as a jsonl file."
      ],
      "metadata": {
        "id": "sS3f6L_zJycQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df.to_json(\"sport2.jsonl\", orient='records', lines=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "huoQnRK-JycQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation tool\n",
        "We can now use a data preparation tool which will suggest a few improvements to our dataset before fine-tuning. Before launching the tool we update the openai library to ensure we're using the latest data preparation tool. We additionally specify `-q` which auto-accepts all suggestions."
      ],
      "metadata": {
        "id": "lWJblmmoJycQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install --upgrade openai"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.6)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs0v6pGiJycQ",
        "outputId": "ff4a09d0-a778-4001-bbc3-49ae00bf6a2e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!openai tools fine_tunes.prepare_data -f sport2.jsonl -q"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your file contains 1197 prompt-completion pairs\n",
            "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
            "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
            "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
            "- There are 11 examples that are very long. These are rows: [134, 200, 281, 320, 404, 595, 704, 838, 1113, 1139, 1174]\n",
            "For conditional generation, and for classification the examples shouldn't be longer than 2048 tokens.\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Recommended] Remove 11 long examples [Y/n]: Y\n",
            "- [Recommended] Add a suffix separator `\\n\\n###\\n\\n` to all prompts [Y/n]: Y\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
            "- [Recommended] Would you like to split into training and validation set? [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified files to `sport2_prepared_train.jsonl` and `sport2_prepared_valid.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"sport2_prepared_train.jsonl\" -v \"sport2_prepared_valid.jsonl\" --compute_classification_metrics --classification_positive_class \" baseball\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt.\n",
            "Once your model starts training, it'll approximately take 30.8 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISLtYmgrJycQ",
        "outputId": "b02ea6c6-1a00-416d-fa1b-8c068426ac99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tool helpfully suggests a few improvements to the dataset and splits the dataset into training and validation set.\n",
        "\n",
        "A suffix between a prompt and a completion is necessary to tell the model that the input text has stopped, and that it now needs to predict the class. Since we use the same separator in each example, the model is able to learn that it is meant to predict either baseball or hockey following the separator.\n",
        "A whitespace prefix in completions is useful, as most word tokens are tokenized with a space prefix.\n",
        "The tool also recognized that this is likely a classification task, so it suggested to split the dataset into training and validation datasets. This will allow us to easily measure expected performance on new data."
      ],
      "metadata": {
        "id": "aWJ2IYnQJycR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning\n",
        "The tool suggests we run the following command to train the dataset. Since this is a classification task, we would like to know what the generalization performance on the provided validation set is for our classification use case. The tool suggests to add `--compute_classification_metrics --classification_positive_class \" baseball\"` in order to compute the classification metrics.\n",
        "\n",
        "We can simply copy the suggested command from the CLI tool. We specifically add `-m ada` to fine-tune a cheaper and faster ada model, which is usually comperable in performance to slower and more expensive models on classification use cases. "
      ],
      "metadata": {
        "id": "rP2CHEuyJycR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!openai -k \"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\" api fine_tunes.create -t \"sport2_prepared_train.jsonl\" -v \"sport2_prepared_valid.jsonl\" --compute_classification_metrics --classification_positive_class \" baseball\" -m ada"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rUpload progress:   0% 0.00/1.52M [00:00<?, ?it/s]\rUpload progress: 100% 1.52M/1.52M [00:00<00:00, 2.01Git/s]\n",
            "Uploaded file from sport2_prepared_train.jsonl: file-iLrr4IHweg2sCCRcYNcBbMtg\n",
            "Upload progress: 100% 387k/387k [00:00<00:00, 845Mit/s]\n",
            "Uploaded file from sport2_prepared_valid.jsonl: file-DS8cp5SwNwdfibqsZCV6dxUv\n",
            "Created fine-tune: ft-LsjnbtINxYNulOroStE3YAc6\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-05-07 07:45:25] Created fine-tune: ft-LsjnbtINxYNulOroStE3YAc6\n",
            "[2023-05-07 07:45:40] Fine-tune costs $0.78\n",
            "[2023-05-07 07:45:40] Fine-tune enqueued. Queue number: 0\n",
            "[2023-05-07 07:45:41] Fine-tune started\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9vSvcwaJycR",
        "outputId": "229eedfd-01ad-4019-9e38-4ef5ba3cfe2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is successfully trained in about ten minutes. We can see the model name is `ada:ft-openai-2021-07-30-12-26-20`, which we can use for doing inference."
      ],
      "metadata": {
        "id": "QZwlRgNcJycR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Advanced] Results and expected model performance\n",
        "We can now download the results file to observe the expected performance on a held out validation set."
      ],
      "metadata": {
        "id": "iEjr-0iLJycR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!openai api fine_tunes.results -i ft-2zaA7qi0rxJduWQpdvOvmGn3 > result.csv"
      ],
      "outputs": [],
      "metadata": {
        "id": "UW_9JUefJycR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "results = pd.read_csv('result.csv')\n",
        "results[results['classification/accuracy'].notnull()].tail(1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "2O3Hsqf1JycR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy reaches 99.6%. On the plot below we can see how accuracy on the validation set increases during the training run. "
      ],
      "metadata": {
        "id": "33k0h7IDJycR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "results[results['classification/accuracy'].notnull()]['classification/accuracy'].plot()"
      ],
      "outputs": [],
      "metadata": {
        "id": "XnJydNs2JycR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the model\n",
        "We can now call the model to get the predictions."
      ],
      "metadata": {
        "id": "kn5AICDeJycR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test = pd.read_json('sport2_prepared_valid.jsonl', lines=True)\n",
        "test.head()"
      ],
      "outputs": [],
      "metadata": {
        "id": "GfvCsR--JycR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to use the same separator following the prompt which we used during fine-tuning. In this case it is `\\n\\n###\\n\\n`. Since we're concerned with classification, we want the temperature to be as low as possible, and we only require one token completion to determine the prediction of the model."
      ],
      "metadata": {
        "id": "nuTS1PzAJycS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ft_model = 'ada:ft-openai-2021-07-30-12-26-20'\n",
        "res = openai.Completion.create(model=ft_model, prompt=test['prompt'][0] + '\\n\\n###\\n\\n', max_tokens=1, temperature=0)\n",
        "res['choices'][0]['text']\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "DaBAk__ZJycS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the log probabilities, we can specify logprobs parameter on the completion request"
      ],
      "metadata": {
        "id": "zXgVQOo8JycS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "res = openai.Completion.create(model=ft_model, prompt=test['prompt'][0] + '\\n\\n###\\n\\n', max_tokens=1, temperature=0, logprobs=2)\n",
        "res['choices'][0]['logprobs']['top_logprobs'][0]"
      ],
      "outputs": [],
      "metadata": {
        "id": "1Hebc0AiJycS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the model predicts hockey as a lot more likely than baseball, which is the correct prediction. By requesting log_probs, we can see the prediction (log) probability for each class."
      ],
      "metadata": {
        "id": "BL3wjnEhJycS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generalization\n",
        "Interestingly, our fine-tuned classifier is quite versatile. Despite being trained on emails to different mailing lists, it also successfully predicts tweets."
      ],
      "metadata": {
        "id": "TOBEBvN2JycS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sample_hockey_tweet = \"\"\"Thank you to the \n",
        "@Canes\n",
        " and all you amazing Caniacs that have been so supportive! You guys are some of the best fans in the NHL without a doubt! Really excited to start this new chapter in my career with the \n",
        "@DetroitRedWings\n",
        " !!\"\"\"\n",
        "res = openai.Completion.create(model=ft_model, prompt=sample_hockey_tweet + '\\n\\n###\\n\\n', max_tokens=1, temperature=0, logprobs=2)\n",
        "res['choices'][0]['text']"
      ],
      "outputs": [],
      "metadata": {
        "id": "C-Xozf3WJycS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sample_baseball_tweet=\"\"\"BREAKING: The Tampa Bay Rays are finalizing a deal to acquire slugger Nelson Cruz from the Minnesota Twins, sources tell ESPN.\"\"\"\n",
        "res = openai.Completion.create(model=ft_model, prompt=sample_baseball_tweet + '\\n\\n###\\n\\n', max_tokens=1, temperature=0, logprobs=2)\n",
        "res['choices'][0]['text']"
      ],
      "outputs": [],
      "metadata": {
        "id": "Q8gTdM8IJycS"
      }
    }
  ],
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.3 64-bit ('base': conda)"
    },
    "interpreter": {
      "hash": "3b138a8faad971cc852f62bcf00f59ea0e31721743ea2c5a866ca26adf572e75"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}